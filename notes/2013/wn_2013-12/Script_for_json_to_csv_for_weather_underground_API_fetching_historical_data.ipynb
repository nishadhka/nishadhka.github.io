{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Script_for_json_to_csv_for_weather_underground_API_fetching_historical_data**\n",
    "\n",
    "1. based on this https://github.com/PythonJournos/LearningPython/blob/master/tutorials/convert_json_to_csv.py\n",
    "a sample script\n",
    "```python\n",
    "import urllib2\n",
    "import json\n",
    "import csv\n",
    "outfile_path='history.csv'\n",
    "writer = csv.writer(open(outfile_path, 'w'))\n",
    "headers = ['date']\n",
    "writer.writerow(headers)\n",
    "req = urllib2.Request(\"http://api.wunderground.com/api/YOUR_KEY/history_20131001/q/India/Coimbatore.json\")\n",
    "opener = urllib2.build_opener()\n",
    "f = opener.open(req)\n",
    "data = json.load(f)\n",
    "for history in data['history']['observations']:\n",
    "       row = []\n",
    "       row.append(str(history['date']['pretty']))\n",
    "       row.append(str(history['tempm']))\n",
    "       writer.writerow(row)\n",
    "```\n",
    "2. Now the url has to be itrated to give a range of historical data required and most important the date range has to set. The date range is based on answer http://stackoverflow.com/questions/1060279/iterating-through-a-range-of-dates-in-python, a sample script\n",
    "```python\n",
    "from datetime import date\n",
    "from dateutil.rrule import rrule, DAILY\n",
    "a = date(2009, 5, 30)\n",
    "b = date(2009, 6, 9)\n",
    "for dt in rrule(DAILY, dtstart=a, until=b):\n",
    "    print dt.strftime(\"%Y-%m-%d\")\n",
    "```\n",
    "1. The url itration based on this answer http://stackoverflow.com/questions/16632569/for-loops-in-python-to-read-long-url-from-shortened-url, a sample code\n",
    "```python\n",
    "import urllib2\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "for x in ('20131011','20131012'):\n",
    "  shortURL = 'http://api.wunderground.com/api/4d09b615cbc7726e/history_'+str(x)+'/q/India/Coimbatore.json'\n",
    "  output = urllib2.urlopen(shortURL)\n",
    "  print output.url\n",
    "```\n",
    "3. now the problem is how to take the for loop date range into the url for looping, long searched for making a list from the print\n",
    "```python\n",
    "dt.strftime(“%Y-%m-%d”)\n",
    "```\n",
    "1. finally got write by empty array . append, hoooorahe! http://learnpythonthehardway.org/book/ex32.html, the sample code become\n",
    "```python\n",
    "import urllib2 from datetime\n",
    "import date from dateutil.rrule\n",
    "import rrule, DAILY\n",
    "a = date(2009, 6, 3)\n",
    "b = date(2009, 6, 9)\n",
    "dtm = []\n",
    "for\n",
    "dt in rrule(DAILY, dtstart=a, until=b): print dt.strftime(“%Y%m%d”)\n",
    "dtm.append(dt.strftime(“%Y%m%d”))\n",
    "print dtm\n",
    "for x in (dtm): shortURL = ‘http://api.wunderground.com/api/YOURKEY/history_’+str(x)+‘/q/India/Coimbatore.json’ output = urllib2.urlopen(shortURL)\n",
    "print output.url ``` the out put looks\n",
    "20090603 20090604 ——— 20090609 [‘20090603’, ‘20090604’, ‘20090605’, ‘20090606’, ‘20090607’, ‘20090608’, ‘20090609’] http://api.wunderground.com/api/YOURKEY/history_20090603/q/India/Coimbatore.json —————- http://api.wunderground.com/api/YOURKEY/history_20090609/q/India/Coimbatore.json\n",
    "```\n",
    "1. now the challenge is how to intgrate above code with csv write code. The solution is another for loop for urllib\n",
    "the final code is\n",
    "```python\n",
    "import urllib2\n",
    "import json\n",
    "import csv\n",
    "from datetime import date\n",
    "from dateutil.rrule import rrule, DAILY\n",
    "outfile_path='history.csv'\n",
    "writer = csv.writer(open(outfile_path, 'w'))\n",
    "headers = ['TimeIST','TemperatureC','Dew PointC','Humidity','Wind SpeedKm/h','Gust SpeedKm/h','Wind DirectionDe','Wind Direction','VisibilityKm','Sea Level PressurehPa','Events','Heatindex','Precipitationmm','Conditions']\n",
    "writer.writerow(headers)\n",
    "a = date(2013, 8, 1)\n",
    "b = date(2013, 8, 2)\n",
    "dtm = []\n",
    "for dt in rrule(DAILY, dtstart=a, until=b):\n",
    "    dtm.append(dt.strftime(\"%Y%m%d\"))\n",
    "for x in (dtm):\n",
    "    url = 'http://api.wunderground.com/api/4d09b615cbc7726e/history_'+str(x)+'/q/India/Coimbatore.json'\n",
    "    req = urllib2.Request(url)\n",
    "    opener = urllib2.build_opener()\n",
    "    f = opener.open(req)\n",
    "    data = json.load(f)\n",
    "for history in data['history']['observations']:\n",
    "       row = []\n",
    "       datewu = history['date']['year']+'-'+history['date']['mon']+'-'+history['date']['mday']+'T'+history['date']['hour']+':'+history['date']['min']+':00.000000+0530'    \n",
    "       row.append(str(datewu))\n",
    "       row.append(str(history['tempm']))\n",
    "       row.append(str(history['dewptm']))\n",
    "       row.append(str(history['hum']))\n",
    "       row.append(str(history['wspdm']))\n",
    "       row.append(str(history['wgustm']))\n",
    "       row.append(str(history['wdird']))\n",
    "       row.append(str(history['wdire']))\n",
    "       row.append(str(history['vism']))\n",
    "       row.append(str(history['pressurem']))\n",
    "       row.append(str(history['windchillm']))\n",
    "       row.append(str(history['heatindexm']))\n",
    "       row.append(str(history['precipm']))\n",
    "       row.append(str(history['conds']))\n",
    "       writer.writerow(row)\n",
    "```\n",
    "1. The aboe code doen’t done the job, it only taking the last date from the date range, the code has to change.the final working code\n",
    "```python\n",
    "import urllib2\n",
    "import json\n",
    "import csv from datetime\n",
    "import date from dateutil.rrule\n",
    "import rrule, DAILY\n",
    "outfile_path=‘history1.csv’\n",
    "writer = csv.writer(open(outfile_path, ‘w’))\n",
    "headers = [‘TimeIST’,‘TemperatureC’,‘Dew PointC’,‘Humidity’,‘Wind SpeedKm/h’,‘Gust SpeedKm/h’,‘Wind DirectionDe’,‘Wind Direction’,‘VisibilityKm’,‘Sea Level PressurehPa’,‘Events’,‘Heatindex’,‘Precipitationmm’,‘Conditions’] writer.writerow(headers)\n",
    "a = date(2013, 8, 5) b = date(2013, 8, 10)\n",
    "dtm = [] for dt in rrule(DAILY, dtstart=a, until=b): # print dt.strftime(“%Y%m%d”) dtm.append(dt.strftime(“%Y%m%d”))\n",
    "dtl = [] for x in (dtm):\n",
    "shortURL = ‘http://api.wunderground.com/api/4d09b615cbc7726e/history_’+str(x)+‘/q/India/Coimbatore.json’ output = urllib2.urlopen(shortURL) # print output.url dtl.append(output.url)\n",
    "print dtl\n",
    "dtd = [] for url in (dtl): req = urllib2.Request(url)\n",
    "opener = urllib2.build_opener()\n",
    "f = opener.open(req) data = json.load(f) # print data dtd.append(data)\n",
    "for d in (dtd): for history in d[‘history’][‘observations’]: if d != history: row = [] datewu = history[‘date’][‘year’]+’-‘+history[’date’][‘mon’]+’-‘+history[’date’][‘mday’]+‘T’+history[‘date’][‘hour’]+’:‘+history[’date’][‘min’]+’:00.000000+0530’\n",
    "row.append(str(datewu)) row.append(str(history[‘tempm’])) row.append(str(history[‘dewptm’])) row.append(str(history[‘hum’])) row.append(str(history[‘wspdm’])) row.append(str(history[‘wgustm’])) row.append(str(history[‘wdird’])) row.append(str(history[‘wdire’])) row.append(str(history[‘vism’])) row.append(str(history[‘pressurem’])) row.append(str(history[‘windchillm’])) row.append(str(history[‘heatindexm’])) row.append(str(history[‘precipm’])) row.append(str(history[‘conds’])) writer.writerow(row)\n",
    "print data\n",
    "```\n",
    "1. Create a csv from Json for WU current observations the non working code for past 5 hours\n",
    "```python\n",
    "import urllib2\n",
    "import json\n",
    "import csv\n",
    "from datetime import date\n",
    "#from dateutil.rrule import rrule, DAILY\n",
    "outfile_path='CART.DAT'\n",
    "writer = csv.writer(open(outfile_path, 'w'))\n",
    "headers = ['urn:ogc:def:parameter:x-istsos:1.0:time:iso8601','urn:ogc:def:parameter:x-istsos:1.0:cbe:aws:dewpont','urn:ogc:def:parameter:x-ists$\n",
    "writer.writerow(headers)\n",
    "req = urllib2.Request(\"http://api.wunderground.com/api/4d09b615cbc7726e/conditions/q/India/Coimbatore.json\")\n",
    "opener = urllib2.build_opener()\n",
    "f = opener.open(req)\n",
    "data = json.load(f)\n",
    "for current_observation in data['current_observation']:\n",
    "     print ['station_id']\n",
    "```\n",
    "1. Working code for converting json into csv\n",
    "```python\n",
    "import csv\n",
    "import json\n",
    "x=\"\"\"[ \n",
    "    { \"pk\": 22, \"model\": \"auth.permission\", \"fields\": \n",
    "        { \"codename\": \"add_logentry\", \"name\": \"Can add log entry\", \"content_type\": 8 } \n",
    "    }, \n",
    "    { \"pk\": 23, \"model\": \"auth.permission\", \"fields\": \n",
    "        { \"codename\": \"change_logentry\", \"name\": \"Can change log entry\", \"content_type\": 8 } \n",
    "    },\n",
    "    { \"pk\": 24, \"model\": \"auth.permission\", \"fields\": \n",
    "        { \"codename\": \"delete_logentry\", \"name\": \"Can delete log entry\", \"content_type\": 8 } \n",
    "    }\n",
    "]\"\"\"\n",
    "x = json.loads(x)\n",
    "f = csv.writer(open(\"test.csv\", \"wb+\"))\n",
    "# Write CSV Header, If you dont need that, remove this line\n",
    "f.writerow([\"pk\", \"model\", \"codename\", \"name\", \"content_type\"])\n",
    "for x in x:\n",
    "    f.writerow([x[\"pk\"], \n",
    "                x[\"model\"], \n",
    "                x[\"fields\"][\"codename\"], \n",
    "                x[\"fields\"][\"name\"],\n",
    "                x[\"fields\"][\"content_type\"]])\n",
    "```\n",
    "1. always getting TypeError: string indices must be integers hrrr\n",
    "1. finally got working code based on experience that, with current json file of single row, it is unnecessary and erroneous to call ‘for loop’, (took 5 hours to realize) and as per this answer http://stackoverflow.com/questions/14784334/python-csv-error-sequence-expected\n",
    "1. so the working code is as follows\n",
    "```python \n",
    "import csv \n",
    "import json \n",
    "import urllib2 \n",
    "from datetime import date \n",
    "outfile_path=‘CART.DAT’ \n",
    "writer = csv.writer(open(outfile_path, ‘w’)) \n",
    "headers = [‘urn:ogc:def:parameter:x-istsos:1.0:time:iso8601’,‘urn:ogc:def:parameter:x-istsos:1.0:cbe:aws:dewpont’] \n",
    "writer.writerow(headers) \n",
    "req = urllib2.Request(“http://api.wunderground.com/api/4d09b615cbc7726e/conditions/q/India/Coimbatore.json”) \n",
    "opener = urllib2.build_opener() \n",
    "f = opener.open(req) \n",
    "data = json.load(f) \n",
    "for data in data: \n",
    "       rows = [data[“current_observation”][“temp_c”]] \n",
    "       writer.writerow(rows)\n",
    "``` \n",
    "1. Now having problem in converting the date time formate of wu date formate to istsos’s. followed this for converting last answer, http://stackoverflow.com/questions/13350909/convert-other-time-values-to-datetime-format-in-python\n",
    "but that answer has a mistake, in specifying the shortened version of month, it should be %b not %m as specified in the answer. this is from http://www.lightbird.net/py-by-example/datetime.date-module.html so the final code for converting the date and making a csv.DAT is this\n",
    "```python\n",
    "import csv\n",
    "import json\n",
    "import urllib2\n",
    "from datetime import datetime\n",
    "outfile_path='CART.DAT'\n",
    "writer = csv.writer(open(outfile_path, 'w'))\n",
    "headers = ['urn:ogc:def:parameter:x-istsos:1.0:time:iso8601','urn:ogc:def:parameter:x-istsos:1.0:cbe:aws:dewpont']\n",
    "writer.writerow(headers)\n",
    "req = urllib2.Request(\"http://api.wunderground.com/api/4d09b615cbc7726e/conditions/q/India/Coimbatore.json\")\n",
    "opener = urllib2.build_opener()\n",
    "f = opener.open(req)\n",
    "data = json.load(f)\n",
    "#for data in data:\n",
    "dateNF = data['current_observation']['observation_time_rfc822'].strip( '+0530' );\n",
    "print dateNF\n",
    "dateITS = datetime.strptime (dateNF, \"%a, %d %b %Y %H:%M:%S \").strftime(\"%Y-%m-%dT%H:%M:%S.000000+0530\")\n",
    "print dateITS\n",
    "rows = [dateITS,data[\"current_observation\"][\"temp_c\"]]\n",
    "writer.writerow(rows)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
